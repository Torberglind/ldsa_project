{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import hdf5_getters\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Row\n",
    "from collections import OrderedDict\n",
    "from pyspark import SparkFiles\n",
    "from tables import *\n",
    "#import pydoop.hdfs as hpath\n",
    "\n",
    "spark_session = SparkSession\\\n",
    "                .builder\\\n",
    "                .master(\"spark://192.168.1.16:7077\") \\\n",
    "                .appName(\"Data Analysis\")\\\n",
    "                .config(\"spark.submit.deployMode\", \"client\")\\\n",
    "                .config(\"spark.dynamicAllocation.enabled\", \"false\")\\\n",
    "                .config(\"spark.cores.max\", \"4\")\\\n",
    "                .config(\"spark.dynamicAllocation.enabled\", \"false\")\\\n",
    "                .config(\"spark.executor.memory\", \"1g\")\\\n",
    "                .getOrCreate()\n",
    "\n",
    "spark_context = spark_session.sparkContext\n",
    "spark_context.addPyFile(\"utils/hdf5_getters.py\")\n",
    "# spark_session.sparkContext.addPyFile(\"utils/hdf5_getters.py\")\n",
    "sqlContext = SQLContext(spark_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def recursive_file_search(rootDir, songs):\n",
    "#     for lists in os.listdir(rootDir):\n",
    "#         path = os.path.join(rootDir, lists)\n",
    "#         if os.path.isdir(path):\n",
    "#             recursive_file_search(path, songs)\n",
    "#         else:\n",
    "#             songs.append(str(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_file_search(rootDir, songs):\n",
    "    for lists in rootDir:\n",
    "        path = hpath.path.join(rootDir, lists)\n",
    "        if hpath.path.isdir(path):\n",
    "            recursive_file_search(path, songs)\n",
    "        else:\n",
    "            songs.append(str(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_h5_file_read(h5filename):\n",
    "    \"\"\"\n",
    "    Open an existing H5 in read mode.\n",
    "    Same function as in hdf5_utils, here so we avoid one import\n",
    "    \"\"\"\n",
    "    return tables.open_file(h5filename, mode='r')\n",
    "\n",
    "def get_song_id(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get song id from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.metadata.songs.cols.song_id[songidx]\n",
    "\n",
    "def get_artist_name(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get artist name from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.metadata.songs.cols.artist_name[songidx]\n",
    "\n",
    "def get_title(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get title from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.metadata.songs.cols.title[songidx]\n",
    "\n",
    "def get_loudness(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get loudness from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.analysis.songs.cols.loudness[songidx]\n",
    "\n",
    "def get_year(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get release year from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.musicbrainz.songs.cols.year[songidx]\n",
    "\n",
    "def get_tempo(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get tempo from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.analysis.songs.cols.tempo[songidx]\n",
    "\n",
    "def get_danceability(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get danceability from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.analysis.songs.cols.danceability[songidx]\n",
    "\n",
    "def get_artist_mbtags(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get artist musicbrainz tag array. Takes care of the proper indexing if we are in aggregate\n",
    "    file. By default, return the array for the first song in the h5 file.\n",
    "    To get a regular numpy ndarray, cast the result to: numpy.array( )\n",
    "    \"\"\"\n",
    "    if h5.root.musicbrainz.songs.nrows == songidx + 1:\n",
    "        return h5.root.musicbrainz.artist_mbtags[h5.root.musicbrainz.songs.cols.idx_artist_mbtags[songidx]:]\n",
    "    return h5.root.musicbrainz.artist_mbtags[h5.root.metadata.songs.cols.idx_artist_mbtags[songidx]:\n",
    "                                             h5.root.metadata.songs.cols.idx_artist_mbtags[songidx+1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "311831"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mypath = \"/home/ubuntu/A.tar.gz/A/MillionSongSubset/data/A/A\"\n",
    "mypath = \"hdfs://192.168.1.16:9000/user/ubuntu/songs_ABC.csv\"\n",
    "\n",
    "songs = []\n",
    "data_frame = spark_session.read\\\n",
    "    .option('header', 'true')\\\n",
    "    .csv(mypath)\\\n",
    "    .cache()\n",
    "\n",
    "data_frame.count()\n",
    "\n",
    "#map(lambda x: x).take(10)\n",
    "#map(lambda x: hdf5_getters.open_h5_file_read(x)).take(10)\n",
    "\n",
    "#.map(lambda x: hdf5_getters.get_title(x)).take(5)\n",
    "\n",
    "# recursive_file_search(mypath, songs)\n",
    "# songs_rdd = spark_context.parallelize(songs)\n",
    "# print(\"All songs in specified directory appended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- track id: string (nullable = true)\n",
      " |-- artist: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- loudness: string (nullable = true)\n",
      " |-- tempo: string (nullable = true)\n",
      " |-- tags: string (nullable = true)\n",
      " |-- release year: string (nullable = true)\n",
      " |-- danceability: string (nullable = true)\n",
      "\n",
      "+------------+------------------+\n",
      "|release year|        avg(tempo)|\n",
      "+------------+------------------+\n",
      "|        1953|119.91335714285714|\n",
      "|        1957|113.82883419689121|\n",
      "|        1987|126.65779720704309|\n",
      "|        1956|115.90801081081081|\n",
      "|        1936|         92.119125|\n",
      "|        1958|115.24875287356323|\n",
      "|        1943|118.66366666666666|\n",
      "|        1972|124.22721928665784|\n",
      "|        1931|          101.9015|\n",
      "|        1988|124.12052522421527|\n",
      "|        1926| 98.41649999999998|\n",
      "|        1938|127.02999999999999|\n",
      "|        1932|110.72800000000001|\n",
      "|        1977| 130.5529619631902|\n",
      "|        1971|124.80250834597874|\n",
      "|        1984|129.13781800197827|\n",
      "|        1982|128.88615700267619|\n",
      "|        1941| 91.43828571428571|\n",
      "|        2005|124.99389527027019|\n",
      "|           0|123.00108945400412|\n",
      "+------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_frame.printSchema()\n",
    "data_frame.groupby('release year')\\\n",
    "    .agg({ 'tempo': 'mean' })\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterate_songs(song):\n",
    "        h5 = open_h5_file_read(song)\n",
    "        track_id = str(get_song_id(h5), \"utf-8\")\n",
    "        artist = str(get_artist_name(h5), \"utf-8\")\n",
    "        title = str(get_title(h5), \"utf-8\")\n",
    "        loudness = float(get_loudness(h5))\n",
    "        release_year = int(get_year(h5))\n",
    "        tempo = float(get_tempo(h5))\n",
    "        danceability = float(get_danceability(h5))\n",
    "\n",
    "        tags = get_artist_mbtags(h5)\n",
    "        tags = tags.tolist()\n",
    "        tags_refined = []\n",
    "        for tag in tags:\n",
    "            tags_refined.append(str(tag, \"utf-8\"))\n",
    "\n",
    "        h5.close()\n",
    "        return {'track_id': track_id,\n",
    "                'artist': artist,\n",
    "                'title': title,\n",
    "                'loudness': loudness,\n",
    "                'release_year': release_year,\n",
    "                'tempo': tempo,\n",
    "                'tags': tags_refined}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_row(d: dict) -> Row:\n",
    "   return Row(**OrderedDict(sorted(d.items())))\n",
    "\n",
    "new_rdd = songs_rdd.map(iterate_songs)\n",
    "\n",
    "df = new_rdd.map(convert_to_row).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.registerTempTable(\"songs\")\n",
    "spark_session.sql(\"select avg(tempo), release_year from songs group by release_year order by avg(tempo) desc\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_context.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
