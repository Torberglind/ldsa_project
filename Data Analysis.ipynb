{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from utils import hdf5_getters\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Row\n",
    "from collections import OrderedDict\n",
    "from pyspark import SparkFiles\n",
    "from tables import *\n",
    "\n",
    "spark_session = SparkSession\\\n",
    "                .builder\\\n",
    "                .master(\"spark://192.168.1.16:7077\") \\\n",
    "                .appName(\"Data Analysis\")\\\n",
    "                .config(\"spark.submit.deployMode\", \"client\")\\\n",
    "                .config(\"spark.dynamicAllocation.enabled\", \"false\")\\\n",
    "                .config(\"spark.cores.max\", \"4\")\\\n",
    "                .config(\"spark.dynamicAllocation.enabled\", \"false\")\\\n",
    "                .config(\"spark.executor.memory\", \"1g\")\\\n",
    "                .getOrCreate()\n",
    "\n",
    "spark_context = spark_session.sparkContext\n",
    "spark_context.addPyFile(\"utils/hdf5_getters.py\")\n",
    "# spark_session.sparkContext.addPyFile(\"utils/hdf5_getters.py\")\n",
    "sqlContext = SQLContext(spark_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hdf5_getters = SparkFiles.get(\"utils/hdf5_getters.py\")\n",
    "# dirr = SparkFiles.getRootDirectory()\n",
    "# with open(SparkFiles.get(\"utils/hdf5_getters.py\")) as fr:\n",
    "#        lines = [line for line in fr]\n",
    "# print(hdf5_getters)\n",
    "def recursive_file_search(rootDir, songs):\n",
    "    for lists in os.listdir(rootDir):\n",
    "        path = os.path.join(rootDir, lists)\n",
    "        if os.path.isdir(path):\n",
    "            recursive_file_search(path, songs)\n",
    "        else:\n",
    "            songs.append(str(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def open_h5_file_read(h5filename):\n",
    "    \"\"\"\n",
    "    Open an existing H5 in read mode.\n",
    "    Same function as in hdf5_utils, here so we avoid one import\n",
    "    \"\"\"\n",
    "    return tables.open_file(h5filename, mode='r')\n",
    "\n",
    "def get_song_id(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get song id from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.metadata.songs.cols.song_id[songidx]\n",
    "\n",
    "def get_artist_name(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get artist name from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.metadata.songs.cols.artist_name[songidx]\n",
    "\n",
    "def get_title(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get title from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.metadata.songs.cols.title[songidx]\n",
    "\n",
    "def get_loudness(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get loudness from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.analysis.songs.cols.loudness[songidx]\n",
    "\n",
    "def get_year(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get release year from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.musicbrainz.songs.cols.year[songidx]\n",
    "\n",
    "def get_tempo(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get tempo from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.analysis.songs.cols.tempo[songidx]\n",
    "\n",
    "def get_danceability(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get danceability from a HDF5 song file, by default the first song in it\n",
    "    \"\"\"\n",
    "    return h5.root.analysis.songs.cols.danceability[songidx]\n",
    "\n",
    "def get_artist_mbtags(h5,songidx=0):\n",
    "    \"\"\"\n",
    "    Get artist musicbrainz tag array. Takes care of the proper indexing if we are in aggregate\n",
    "    file. By default, return the array for the first song in the h5 file.\n",
    "    To get a regular numpy ndarray, cast the result to: numpy.array( )\n",
    "    \"\"\"\n",
    "    if h5.root.musicbrainz.songs.nrows == songidx + 1:\n",
    "        return h5.root.musicbrainz.artist_mbtags[h5.root.musicbrainz.songs.cols.idx_artist_mbtags[songidx]:]\n",
    "    return h5.root.musicbrainz.artist_mbtags[h5.root.metadata.songs.cols.idx_artist_mbtags[songidx]:\n",
    "                                             h5.root.metadata.songs.cols.idx_artist_mbtags[songidx+1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mypath = \"/home/ubuntu/A.tar.gz/A/MillionSongSubset/data/A/A\"\n",
    "songs = []\n",
    "recursive_file_search(mypath, songs)\n",
    "songs_rdd = spark_context.parallelize(songs)\n",
    "print(\"All songs in specified directory appended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def iterate_songs(song):\n",
    "#         h5 = hdf5_getters.open_h5_file_read(song)\n",
    "#         track_id = str(hdf5_getters.get_song_id(h5), \"utf-8\")\n",
    "#         artist = str(hdf5_getters.get_artist_name(h5), \"utf-8\")\n",
    "#         title = str(hdf5_getters.get_title(h5), \"utf-8\")\n",
    "#         loudness = float(hdf5_getters.get_loudness(h5))\n",
    "#         release_year = int(hdf5_getters.get_year(h5))\n",
    "#         tempo = float(hdf5_getters.get_tempo(h5))\n",
    "#         danceability = float(hdf5_getters.get_danceability(h5))\n",
    "\n",
    "#         tags = hdf5_getters.get_artist_mbtags(h5)\n",
    "#         tags = tags.tolist()\n",
    "#         tags_refined = []\n",
    "#         for tag in tags:\n",
    "#             tags_refined.append(str(tag, \"utf-8\"))\n",
    "\n",
    "#         h5.close()\n",
    "#         return {'track_id': track_id,\n",
    "#                 'artist': artist,\n",
    "#                 'title': title,\n",
    "#                 'loudness': loudness,\n",
    "#                 'release_year': release_year,\n",
    "#                 'tempo': tempo,\n",
    "#                 'tags': tags_refined}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterate_songs(song):\n",
    "        h5 = open_h5_file_read(song)\n",
    "        track_id = str(get_song_id(h5), \"utf-8\")\n",
    "        artist = str(get_artist_name(h5), \"utf-8\")\n",
    "        title = str(get_title(h5), \"utf-8\")\n",
    "        loudness = float(get_loudness(h5))\n",
    "        release_year = int(get_year(h5))\n",
    "        tempo = float(get_tempo(h5))\n",
    "        danceability = float(get_danceability(h5))\n",
    "\n",
    "        tags = get_artist_mbtags(h5)\n",
    "        tags = tags.tolist()\n",
    "        tags_refined = []\n",
    "        for tag in tags:\n",
    "            tags_refined.append(str(tag, \"utf-8\"))\n",
    "\n",
    "        h5.close()\n",
    "        return {'track_id': track_id,\n",
    "                'artist': artist,\n",
    "                'title': title,\n",
    "                'loudness': loudness,\n",
    "                'release_year': release_year,\n",
    "                'tempo': tempo,\n",
    "                'tags': tags_refined}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_row(d: dict) -> Row:\n",
    "   return Row(**OrderedDict(sorted(d.items())))\n",
    "\n",
    "new_rdd = songs_rdd.map(iterate_songs)\n",
    "\n",
    "df = new_rdd.map(convert_to_row).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.registerTempTable(\"songs\")\n",
    "spark_session.sql(\"select avg(tempo), release_year from songs group by release_year order by avg(tempo) desc\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark_context.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
